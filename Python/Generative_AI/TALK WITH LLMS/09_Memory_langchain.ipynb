{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer Memory\n",
    "* ConversationBufferMemory keeps a list of chat messages in a buffer and passes those into the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bappy Ahmed\\AppData\\Local\\Temp\\ipykernel_3068\\2025338751.py:24: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  conversation = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bappy Ahmed\\AppData\\Local\\Temp\\ipykernel_3068\\2596321432.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  conversation({\"question\": \"hi\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'hi',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How are you today?')],\n",
       " 'text': 'Hello! How are you today?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Bappy and I have moved 33 times.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is Bappy and I have moved 33 times.',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How are you today?'),\n",
       "  HumanMessage(content='My name is Bappy and I have moved 33 times.'),\n",
       "  AIMessage(content='Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What has been your favorite place to live so far?')],\n",
       " 'text': 'Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What has been your favorite place to live so far?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"My name is Bappy and I have moved 33 times.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Bappy and I have moved 33 times.\n",
      "AI: Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What has been your favorite place to live so far?\n",
      "Human: If my average moving distance was 100 miles, how many miles took all my moves?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'If my average moving distance was 100 miles, how many miles took all my moves?',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How are you today?'),\n",
       "  HumanMessage(content='My name is Bappy and I have moved 33 times.'),\n",
       "  AIMessage(content='Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What has been your favorite place to live so far?'),\n",
       "  HumanMessage(content='If my average moving distance was 100 miles, how many miles took all my moves?'),\n",
       "  AIMessage(content=\"If you have moved 33 times and each move was an average of 100 miles, then the total distance you have moved is 33 times 100 miles, which equals 3300 miles. That's quite a journey!\")],\n",
       " 'text': \"If you have moved 33 times and each move was an average of 100 miles, then the total distance you have moved is 33 times 100 miles, which equals 3300 miles. That's quite a journey!\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"If my average moving distance was 100 miles, how many miles took all my moves?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Bappy and I have moved 33 times.\n",
      "AI: Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What has been your favorite place to live so far?\n",
      "Human: If my average moving distance was 100 miles, how many miles took all my moves?\n",
      "AI: If you have moved 33 times and each move was an average of 100 miles, then the total distance you have moved is 33 times 100 miles, which equals 3300 miles. That's quite a journey!\n",
      "Human: Do you remember my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Do you remember my name?',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How are you today?'),\n",
       "  HumanMessage(content='My name is Bappy and I have moved 33 times.'),\n",
       "  AIMessage(content='Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What has been your favorite place to live so far?'),\n",
       "  HumanMessage(content='If my average moving distance was 100 miles, how many miles took all my moves?'),\n",
       "  AIMessage(content=\"If you have moved 33 times and each move was an average of 100 miles, then the total distance you have moved is 33 times 100 miles, which equals 3300 miles. That's quite a journey!\"),\n",
       "  HumanMessage(content='Do you remember my name?'),\n",
       "  AIMessage(content='Yes, I remember your name, Bappy! If you have any other questions or just want to chat, feel free to let me know.')],\n",
       " 'text': 'Yes, I remember your name, Bappy! If you have any other questions or just want to chat, feel free to let me know.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"Do you remember my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='hi'), AIMessage(content='Hello! How are you today?'), HumanMessage(content='My name is Bappy and I have moved 33 times.'), AIMessage(content='Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What has been your favorite place to live so far?'), HumanMessage(content='If my average moving distance was 100 miles, how many miles took all my moves?'), AIMessage(content=\"If you have moved 33 times and each move was an average of 100 miles, then the total distance you have moved is 33 times 100 miles, which equals 3300 miles. That's quite a journey!\"), HumanMessage(content='Do you remember my name?'), AIMessage(content='Yes, I remember your name, Bappy! If you have any other questions or just want to chat, feel free to let me know.')]\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Buffer Window Memory\n",
    "Similar to the previous one, but **you can limit the number of conversational exchanges stored in memory**. For example, you can set it so it only remembers the last 3 questions and answers of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bappy Ahmed\\AppData\\Local\\Temp\\ipykernel_3068\\2450156885.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  conversation_window = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "conversation_window = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = window_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Bappy\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, my name is Bappy',\n",
       " 'history': '',\n",
       " 'response': \"Hello Bappy! It's nice to meet you. How can I assist you today?\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"Hi, my name is Bappy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Bappy\n",
      "AI: Hello Bappy! It's nice to meet you. How can I assist you today?\n",
      "Human: My favorite color is blue\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favorite color is blue',\n",
       " 'history': \"Human: Hi, my name is Bappy\\nAI: Hello Bappy! It's nice to meet you. How can I assist you today?\",\n",
       " 'response': \"Blue is a beautiful color! It's often associated with calmness and tranquility. Do you have a specific shade of blue that you prefer, like navy blue or sky blue?\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"My favorite color is blue\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Bappy\n",
      "AI: Hello Bappy! It's nice to meet you. How can I assist you today?\n",
      "Human: My favorite color is blue\n",
      "AI: Blue is a beautiful color! It's often associated with calmness and tranquility. Do you have a specific shade of blue that you prefer, like navy blue or sky blue?\n",
      "Human: My favorite animals are dogs\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favorite animals are dogs',\n",
       " 'history': \"Human: Hi, my name is Bappy\\nAI: Hello Bappy! It's nice to meet you. How can I assist you today?\\nHuman: My favorite color is blue\\nAI: Blue is a beautiful color! It's often associated with calmness and tranquility. Do you have a specific shade of blue that you prefer, like navy blue or sky blue?\",\n",
       " 'response': 'Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a golden retriever, labrador, or german shepherd?'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"My favorite animals are dogs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Bappy\n",
      "AI: Hello Bappy! It's nice to meet you. How can I assist you today?\n",
      "Human: My favorite color is blue\n",
      "AI: Blue is a beautiful color! It's often associated with calmness and tranquility. Do you have a specific shade of blue that you prefer, like navy blue or sky blue?\n",
      "Human: My favorite animals are dogs\n",
      "AI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a golden retriever, labrador, or german shepherd?\n",
      "Human: I like to drive a vespa scooter in the city\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I like to drive a vespa scooter in the city',\n",
       " 'history': \"Human: Hi, my name is Bappy\\nAI: Hello Bappy! It's nice to meet you. How can I assist you today?\\nHuman: My favorite color is blue\\nAI: Blue is a beautiful color! It's often associated with calmness and tranquility. Do you have a specific shade of blue that you prefer, like navy blue or sky blue?\\nHuman: My favorite animals are dogs\\nAI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a golden retriever, labrador, or german shepherd?\",\n",
       " 'response': 'That sounds like a fun way to get around the city! Vespas are stylish and convenient for navigating through urban areas. Do you have a favorite model or color of Vespa that you like to ride?'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"I like to drive a vespa scooter in the city\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favorite color is blue\n",
      "AI: Blue is a beautiful color! It's often associated with calmness and tranquility. Do you have a specific shade of blue that you prefer, like navy blue or sky blue?\n",
      "Human: My favorite animals are dogs\n",
      "AI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a golden retriever, labrador, or german shepherd?\n",
      "Human: I like to drive a vespa scooter in the city\n",
      "AI: That sounds like a fun way to get around the city! Vespas are stylish and convenient for navigating through urban areas. Do you have a favorite model or color of Vespa that you like to ride?\n",
      "Human: My favorite city is San Francisco\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favorite city is San Francisco',\n",
       " 'history': \"Human: My favorite color is blue\\nAI: Blue is a beautiful color! It's often associated with calmness and tranquility. Do you have a specific shade of blue that you prefer, like navy blue or sky blue?\\nHuman: My favorite animals are dogs\\nAI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a golden retriever, labrador, or german shepherd?\\nHuman: I like to drive a vespa scooter in the city\\nAI: That sounds like a fun way to get around the city! Vespas are stylish and convenient for navigating through urban areas. Do you have a favorite model or color of Vespa that you like to ride?\",\n",
       " 'response': 'San Francisco is a vibrant city with beautiful views, diverse culture, and iconic landmarks like the Golden Gate Bridge and Alcatraz Island. Have you visited San Francisco before, or do you dream of exploring its hills and neighborhoods?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"My favorite city is San Francisco\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favorite animals are dogs\n",
      "AI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a golden retriever, labrador, or german shepherd?\n",
      "Human: I like to drive a vespa scooter in the city\n",
      "AI: That sounds like a fun way to get around the city! Vespas are stylish and convenient for navigating through urban areas. Do you have a favorite model or color of Vespa that you like to ride?\n",
      "Human: My favorite city is San Francisco\n",
      "AI: San Francisco is a vibrant city with beautiful views, diverse culture, and iconic landmarks like the Golden Gate Bridge and Alcatraz Island. Have you visited San Francisco before, or do you dream of exploring its hills and neighborhoods?\n",
      "Human: What is my favorite color?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my favorite color?',\n",
       " 'history': 'Human: My favorite animals are dogs\\nAI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a golden retriever, labrador, or german shepherd?\\nHuman: I like to drive a vespa scooter in the city\\nAI: That sounds like a fun way to get around the city! Vespas are stylish and convenient for navigating through urban areas. Do you have a favorite model or color of Vespa that you like to ride?\\nHuman: My favorite city is San Francisco\\nAI: San Francisco is a vibrant city with beautiful views, diverse culture, and iconic landmarks like the Golden Gate Bridge and Alcatraz Island. Have you visited San Francisco before, or do you dream of exploring its hills and neighborhoods?',\n",
       " 'response': \"I'm sorry, I do not have that information. Would you like to share your favorite color with me?\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"What is my favorite color?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I like to drive a vespa scooter in the city\n",
      "AI: That sounds like a fun way to get around the city! Vespas are stylish and convenient for navigating through urban areas. Do you have a favorite model or color of Vespa that you like to ride?\n",
      "Human: My favorite city is San Francisco\n",
      "AI: San Francisco is a vibrant city with beautiful views, diverse culture, and iconic landmarks like the Golden Gate Bridge and Alcatraz Island. Have you visited San Francisco before, or do you dream of exploring its hills and neighborhoods?\n",
      "Human: What is my favorite color?\n",
      "AI: I'm sorry, I do not have that information. Would you like to share your favorite color with me?\n",
      "Human: What is my favorite city?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my favorite city?',\n",
       " 'history': \"Human: I like to drive a vespa scooter in the city\\nAI: That sounds like a fun way to get around the city! Vespas are stylish and convenient for navigating through urban areas. Do you have a favorite model or color of Vespa that you like to ride?\\nHuman: My favorite city is San Francisco\\nAI: San Francisco is a vibrant city with beautiful views, diverse culture, and iconic landmarks like the Golden Gate Bridge and Alcatraz Island. Have you visited San Francisco before, or do you dream of exploring its hills and neighborhoods?\\nHuman: What is my favorite color?\\nAI: I'm sorry, I do not have that information. Would you like to share your favorite color with me?\",\n",
       " 'response': 'Your favorite city is San Francisco. It is a vibrant city with beautiful views, diverse culture, and iconic landmarks like the Golden Gate Bridge and Alcatraz Island. Have you visited San Francisco before, or do you dream of exploring its hills and neighborhoods?'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"What is my favorite city?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Message History\n",
    "* Save list of chat messages and then fetch them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
